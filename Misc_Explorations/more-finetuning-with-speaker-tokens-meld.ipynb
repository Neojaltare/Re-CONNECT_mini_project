{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":439701,"sourceType":"modelInstanceVersion","modelInstanceId":358448,"modelId":379766}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport pickle\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom transformers import RobertaTokenizer, RobertaModel\nfrom datasets import Dataset\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\n!pip install --quiet bertopic\n!pip install --quiet sentence-transformers\n!pip install --quiet keybert\n\n# import warnings\n# warnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:47:56.376859Z","iopub.execute_input":"2025-06-21T16:47:56.377149Z","iopub.status.idle":"2025-06-21T16:48:06.380145Z","shell.execute_reply.started":"2025-06-21T16:47:56.377129Z","shell.execute_reply":"2025-06-21T16:48:06.379362Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/roberta_finetuned_meld/pytorch/fine-tuned_1/1/test_sent_emo.csv\n/kaggle/input/roberta_finetuned_meld/pytorch/fine-tuned_1/1/dev_sent_emo.csv\n/kaggle/input/roberta_finetuned_meld/pytorch/fine-tuned_1/1/train_sent_emo.csv\n/kaggle/input/roberta_finetuned_meld/pytorch/fine-tuned_1/1/best_emotion_model_5.pt\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Path to CSVs\ntrain_df = pd.read_csv('/kaggle/input/roberta_finetuned_meld/pytorch/fine-tuned_1/1/train_sent_emo.csv')\ndev_df = pd.read_csv('/kaggle/input/roberta_finetuned_meld/pytorch/fine-tuned_1/1/dev_sent_emo.csv')\ntest_df = pd.read_csv('/kaggle/input/roberta_finetuned_meld/pytorch/fine-tuned_1/1/test_sent_emo.csv')\nprint(train_df.columns)\ntrain_df.head()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:48:20.656909Z","iopub.execute_input":"2025-06-21T16:48:20.657701Z","iopub.status.idle":"2025-06-21T16:48:20.721460Z","shell.execute_reply.started":"2025-06-21T16:48:20.657669Z","shell.execute_reply":"2025-06-21T16:48:20.720858Z"}},"outputs":[{"name":"stdout","text":"Index(['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID',\n       'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime'],\n      dtype='object')\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"   Sr No.                                          Utterance          Speaker  \\\n0       1  also I was the point person on my companys tr...         Chandler   \n1       2                   You mustve had your hands full.  The Interviewer   \n2       3                            That I did. That I did.         Chandler   \n3       4      So lets talk a little bit about your duties.  The Interviewer   \n4       5                             My duties?  All right.         Chandler   \n\n    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n0   neutral   neutral            0             0       8       21   \n1   neutral   neutral            0             1       8       21   \n2   neutral   neutral            0             2       8       21   \n3   neutral   neutral            0             3       8       21   \n4  surprise  positive            0             4       8       21   \n\n      StartTime       EndTime  \n0  00:16:16,059  00:16:21,731  \n1  00:16:21,940  00:16:23,442  \n2  00:16:23,442  00:16:26,389  \n3  00:16:26,820  00:16:29,572  \n4  00:16:34,452  00:16:40,917  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sr No.</th>\n      <th>Utterance</th>\n      <th>Speaker</th>\n      <th>Emotion</th>\n      <th>Sentiment</th>\n      <th>Dialogue_ID</th>\n      <th>Utterance_ID</th>\n      <th>Season</th>\n      <th>Episode</th>\n      <th>StartTime</th>\n      <th>EndTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>also I was the point person on my companys tr...</td>\n      <td>Chandler</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>21</td>\n      <td>00:16:16,059</td>\n      <td>00:16:21,731</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>You mustve had your hands full.</td>\n      <td>The Interviewer</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8</td>\n      <td>21</td>\n      <td>00:16:21,940</td>\n      <td>00:16:23,442</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>That I did. That I did.</td>\n      <td>Chandler</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>0</td>\n      <td>2</td>\n      <td>8</td>\n      <td>21</td>\n      <td>00:16:23,442</td>\n      <td>00:16:26,389</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>So lets talk a little bit about your duties.</td>\n      <td>The Interviewer</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>0</td>\n      <td>3</td>\n      <td>8</td>\n      <td>21</td>\n      <td>00:16:26,820</td>\n      <td>00:16:29,572</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>My duties?  All right.</td>\n      <td>Chandler</td>\n      <td>surprise</td>\n      <td>positive</td>\n      <td>0</td>\n      <td>4</td>\n      <td>8</td>\n      <td>21</td>\n      <td>00:16:34,452</td>\n      <td>00:16:40,917</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"num_speakers = []\nfor thisid in train_df['Dialogue_ID'].unique():\n    this_dialogue = train_df[train_df['Dialogue_ID'] == thisid]\n    num_speakers.append(len(this_dialogue['Speaker'].unique()))\n\nprint(np.max(num_speakers))\nplt.hist((num_speakers))\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:48:33.664043Z","iopub.execute_input":"2025-06-21T16:48:33.664316Z","iopub.status.idle":"2025-06-21T16:48:34.096532Z","shell.execute_reply.started":"2025-06-21T16:48:33.664298Z","shell.execute_reply":"2025-06-21T16:48:34.095598Z"}},"outputs":[{"name":"stdout","text":"9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"# Here I redefine the custom model class and reload the trained weights\n# We also extend the length of the tokenizer to accomodate the speaker tokens\nmodel = RobertaModel.from_pretrained('roberta-base')\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nspecial_speaker_tokens = [f\"<speaker{i}>\" for i in range(1, 10)]  # speaker1 to speaker9\ntokenizer.add_special_tokens({'additional_special_tokens': special_speaker_tokens})\nmax_length = tokenizer.model_max_length\nsep_token = tokenizer.sep_token\n\n# Freeze all layers first\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Unfreeze last 2 layers of the encoder\nfor layer in model.encoder.layer[-2:]:\n    for param in layer.parameters():\n        param.requires_grad = True\n\nclass RobertaForEmotionClassification(nn.Module):\n    def __init__(self, model, num_labels):\n        super().__init__()\n        self.roberta = model\n        self.dropout = nn.Dropout(p=0.1)\n        self.classifier = nn.Linear(768, num_labels)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout(cls_output)\n        return self.classifier(cls_output)\n\n# Instantiate model\nnum_labels = 7  # e.g. 7 emotions\nFull_model = RobertaForEmotionClassification(model, num_labels)\n\n# Load the trained model for F1 score\nmodel_path = \"/kaggle/input/roberta_finetuned_meld/pytorch/fine-tuned_1/1/best_emotion_model_5.pt\"\ncheckpoint = torch.load(model_path, map_location=torch.device('cpu'))\n\nbase_model = RobertaModel.from_pretrained(\"roberta-base\")\nFull_model = RobertaForEmotionClassification(base_model, num_labels)\nFull_model.load_state_dict(checkpoint['model_state_dict'])\nFull_model.roberta.resize_token_embeddings(len(tokenizer))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:21:18.493548Z","iopub.execute_input":"2025-06-21T13:21:18.494297Z","iopub.status.idle":"2025-06-21T13:21:20.211356Z","shell.execute_reply.started":"2025-06-21T13:21:18.494273Z","shell.execute_reply":"2025-06-21T13:21:20.210684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef build_dynamic_context_inputs(df):\n    inputs = []\n    labels = []\n\n    for dialog_id in df['Dialogue_ID'].unique():\n        dialog = df[df['Dialogue_ID'] == dialog_id].sort_values('Utterance_ID')\n        utterances = dialog['Utterance'].tolist()\n        speakers = dialog['Speaker'].tolist()\n        emotions = dialog['Emotion'].tolist()\n\n        # Create speaker mapping for this dialogue\n        unique_speakers = sorted(set(speakers))\n        speaker_map = {name: f\"<speaker{i+1}>\" for i, name in enumerate(unique_speakers)}\n\n        for idx in range(len(utterances)):\n            context = []\n            token_count = 0\n            \n            # Start from current utterance and go backward\n            for i in range(idx, -1, -1):\n                speaker_tag = speaker_map[speakers[i]]\n                text_piece = f\"{speaker_tag}: {utterances[i]}\"\n                tokens = tokenizer.tokenize(text_piece)\n                token_count += len(tokens) + 1  # +1 for separator\n\n                if token_count >= max_length:\n                    break\n\n                context.insert(0, text_piece)  # prepend so order is preserved\n\n            input_text = f\" {sep_token} \".join(context)\n            inputs.append(input_text)\n            labels.append(emotions[idx])\n\n    return inputs, labels\n\ntrain_inputs, train_labels = build_dynamic_context_inputs(train_df)\ntest_inputs, test_labels = build_dynamic_context_inputs(test_df)\ndev_inputs, dev_labels = build_dynamic_context_inputs(dev_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:21:21.808643Z","iopub.execute_input":"2025-06-21T13:21:21.808917Z","iopub.status.idle":"2025-06-21T13:21:28.955621Z","shell.execute_reply.started":"2025-06-21T13:21:21.808896Z","shell.execute_reply":"2025-06-21T13:21:28.955083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build new DataFrame from contextual inputs\nlabel2id = {label: i for i, label in enumerate(sorted(set(train_labels)))} # Dict that maps each label to an integer\nencoded_labels = [label2id[label] for label in train_labels]\n\n# Now create the dataframe\ndata_dict = {\n    \"text\": train_inputs,\n    \"label\": encoded_labels\n}\ncontext_df = pd.DataFrame(data_dict)\ntrain_dataset = Dataset.from_pandas(context_df)\n\n# Function to tokenize the batch\ndef tokenize_batch(batch):\n    return tokenizer(batch['text'],\n                     padding='max_length',\n                     truncation=True,\n                     max_length=512,\n                     return_attention_mask=True)\n\n# Apply tokenizer\ntrain_tokenized = train_dataset.map(tokenize_batch, batched=True, batch_size=32)\n\n# Prepare for PyTorch\ntrain_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n\n# Sanity check\nprint(train_tokenized[0].keys())\n\n\n# Now for the test set\ntest_label2id = {label: i for i, label in enumerate(sorted(set(test_labels)))} # Dict that maps each label to an integer\ntest_encoded_labels = [test_label2id[label] for label in test_labels]\ntest_data_dict = {\n    \"text\": test_inputs,\n    \"label\": test_encoded_labels\n}\ncontext_df = pd.DataFrame(test_data_dict)\ntest_dataset = Dataset.from_pandas(context_df)\ntest_tokenized = test_dataset.map(tokenize_batch, batched=True, batch_size=32)\ntest_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n\n# dev set\ndev_label2id = {label: i for i, label in enumerate(sorted(set(dev_labels)))} # Dict that maps each label to an integer\ndev_encoded_labels = [dev_label2id[label] for label in dev_labels]\ndev_data_dict = {\n    \"text\": dev_inputs,\n    \"label\": dev_encoded_labels\n}\ncontext_df = pd.DataFrame(dev_data_dict)\ndev_dataset = Dataset.from_pandas(context_df)\ndev_tokenized = dev_dataset.map(tokenize_batch, batched=True, batch_size=32)\ndev_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n\n\n# Create dataloaders for train and dev sets (and maybe also test set)\nfrom torch.utils.data import DataLoader\ntrain_loader = DataLoader(train_tokenized, batch_size=16, shuffle=True)\ndev_loader = DataLoader(dev_tokenized, batch_size=16)\ntest_loader = DataLoader(test_tokenized, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:21:28.956866Z","iopub.execute_input":"2025-06-21T13:21:28.957164Z","iopub.status.idle":"2025-06-21T13:21:44.143235Z","shell.execute_reply.started":"2025-06-21T13:21:28.957138Z","shell.execute_reply":"2025-06-21T13:21:44.142333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare for training\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nFull_model.to(device)\noptimizer = torch.optim.AdamW(Full_model.parameters(), lr=2e-5)\ncriterion = nn.CrossEntropyLoss()\n\nfrom transformers import get_linear_schedule_with_warmup\n\nepochs = 15\ntotal_steps = len(train_loader) * epochs\nwarmup_steps = int(0.1 * total_steps)\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=warmup_steps,\n    num_training_steps=total_steps\n)\n\n# Store all metrics\nall_train_batch_losses = []\nall_val_batch_losses = []\nall_train_batch_acc = []\nall_val_batch_acc = []\nepoch_train_accuracies = []\nepoch_val_accuracies = []\nepoch_train_losses = []\nepoch_val_losses = []\nall_learning_rates = []\nbest_val_loss = float('inf')\n\nfor epoch in range(epochs):\n    Full_model.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    epoch_batch_losses = []\n    epoch_batch_acc = []\n\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        optimizer.zero_grad()\n        outputs = Full_model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        current_lr = scheduler.get_last_lr()[0]\n        all_learning_rates.append(current_lr)\n\n        loss_value = loss.item()\n        train_loss += loss_value\n        epoch_batch_losses.append(loss_value)\n\n        _, preds = torch.max(outputs, dim=1)\n        batch_correct = (preds == labels).sum().item()\n        correct += batch_correct\n        total += labels.size(0)\n\n        batch_acc = batch_correct / labels.size(0)\n        epoch_batch_acc.append(batch_acc)\n\n    avg_loss = train_loss / len(train_loader)\n    accuracy = correct / total\n\n    print(f\"Epoch {epoch+1}: LR = {current_lr:.6f}\")\n    print(f\"Train loss: {avg_loss:.4f} | Train accuracy: {accuracy:.4f}\")\n\n    all_train_batch_losses.extend(epoch_batch_losses)\n    all_train_batch_acc.extend(epoch_batch_acc)\n    epoch_train_losses.append(avg_loss)\n    epoch_train_accuracies.append(accuracy)\n\n    # Validation loop\n    Full_model.eval()\n    val_loss = 0\n    correct = 0\n    total = 0\n    val_epoch_losses = []\n    val_epoch_acc = []\n\n    with torch.no_grad():\n        for batch in tqdm(dev_loader, desc=\"Validation\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = Full_model(input_ids=input_ids, attention_mask=attention_mask)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n            val_epoch_losses.append(loss.item())\n\n            _, preds = torch.max(outputs, dim=1)\n            batch_correct = (preds == labels).sum().item()\n            correct += batch_correct\n            total += labels.size(0)\n\n            batch_acc = batch_correct / labels.size(0)\n            val_epoch_acc.append(batch_acc)\n\n    avg_val_loss = val_loss / len(dev_loader)\n    val_accuracy = correct / total\n\n    print(f\"Val loss: {avg_val_loss:.4f} | Val accuracy: {val_accuracy:.4f}\")\n\n    all_val_batch_losses.extend(val_epoch_losses)\n    all_val_batch_acc.extend(val_epoch_acc)\n    epoch_val_losses.append(avg_val_loss)\n    epoch_val_accuracies.append(val_accuracy)\n\n    # Save only if validation improves\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        checkpoint_path = f\"/kaggle/working/Extended_Token_model_{epoch+1}.pt\"\n        torch.save({\n            'model_state_dict': Full_model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'epoch': epoch,\n            'val_loss': avg_val_loss\n        }, checkpoint_path)\n        print(f\"📈 New best model saved at {checkpoint_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:48:19.404545Z","iopub.execute_input":"2025-06-21T13:48:19.405183Z","iopub.status.idle":"2025-06-21T16:31:38.809068Z","shell.execute_reply.started":"2025-06-21T13:48:19.405158Z","shell.execute_reply":"2025-06-21T16:31:38.808443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(all_train_batch_losses)),\nprint(len(all_val_batch_losses)),\nprint(len(all_train_batch_acc)),\nprint(len(all_val_batch_acc)),\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:35:07.764733Z","iopub.execute_input":"2025-06-21T16:35:07.765004Z","iopub.status.idle":"2025-06-21T16:35:07.769964Z","shell.execute_reply.started":"2025-06-21T16:35:07.764987Z","shell.execute_reply":"2025-06-21T16:35:07.769214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save training metrics\ntrain_metrics_df = pd.DataFrame({\n    'train_batch_loss': all_train_batch_losses,\n    'train_batch_acc': all_train_batch_acc,\n    'learning_rate': all_learning_rates\n})\ntrain_metrics_df.to_csv('/kaggle/working/train_batch_metrics.csv', index=False)\n\n# Save validation metrics\nval_metrics_df = pd.DataFrame({\n    'val_batch_loss': all_val_batch_losses,\n    'val_batch_acc': all_val_batch_acc\n})\nval_metrics_df.to_csv('/kaggle/working/val_batch_metrics.csv', index=False)\n\nepoch_metrics_df = pd.DataFrame({\n    'epoch_train_loss': epoch_train_losses,\n    'epoch_val_loss': epoch_val_losses,\n    'epoch_train_acc': epoch_train_accuracies,\n    'epoch_val_acc': epoch_val_accuracies,\n})\n\nepoch_metrics_df.to_csv('/kaggle/working/epoch_metrics.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:37:25.941901Z","iopub.execute_input":"2025-06-21T16:37:25.942646Z","iopub.status.idle":"2025-06-21T16:37:25.993468Z","shell.execute_reply.started":"2025-06-21T16:37:25.942625Z","shell.execute_reply":"2025-06-21T16:37:25.992876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nplt.plot(epoch_train_losses, label = 'Training loss')\nplt.plot(epoch_val_losses, label = 'Validation loss')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"checkpoint_path = f\"/kaggle/working/Overfitted_Extended_Token_model.pt\"\ntorch.save({\n    'model_state_dict': Full_model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'scheduler_state_dict': scheduler.state_dict(),\n    'epoch': epoch,\n    'val_loss': avg_val_loss\n}, checkpoint_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:31:56.967532Z","iopub.execute_input":"2025-06-21T16:31:56.967816Z","iopub.status.idle":"2025-06-21T16:31:59.016603Z","shell.execute_reply.started":"2025-06-21T16:31:56.967797Z","shell.execute_reply":"2025-06-21T16:31:59.015808Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ====== Evaluation on Test Set ======\nFull_model.eval()\ntest_loss = 0\ncorrect = 0\ntotal = 0\ntest_batch_losses = []\ntest_batch_acc = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Testing\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        outputs = Full_model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = criterion(outputs, labels)\n\n        test_loss += loss.item()\n        test_batch_losses.append(loss.item())\n\n        _, preds = torch.max(outputs, dim=1)\n        batch_correct = (preds == labels).sum().item()\n        correct += batch_correct\n        total += labels.size(0)\n\n        batch_acc = batch_correct / labels.size(0)\n        test_batch_acc.append(batch_acc)\n\n# Compute final test loss and accuracy\navg_test_loss = test_loss / len(test_loader)\ntest_accuracy = correct / total\n\nprint(f\"\\n Test Loss: {avg_test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\n\n# Optionally, save test metrics\nimport pandas as pd\n\ntest_metrics_df = pd.DataFrame({\n    'test_batch_loss': test_batch_losses,\n    'test_batch_acc': test_batch_acc\n})\ntest_metrics_df.to_csv('/kaggle/working/test_metrics.csv', index=False)\nprint(\"📁 Saved test metrics to /kaggle/working/test_metrics.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:39:10.059468Z","iopub.execute_input":"2025-06-21T16:39:10.059748Z","iopub.status.idle":"2025-06-21T16:39:49.798971Z","shell.execute_reply.started":"2025-06-21T16:39:10.059729Z","shell.execute_reply":"2025-06-21T16:39:49.798221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T11:01:58.023832Z","iopub.execute_input":"2025-06-21T11:01:58.024584Z","iopub.status.idle":"2025-06-21T11:02:08.58214Z","shell.execute_reply.started":"2025-06-21T11:01:58.024563Z","shell.execute_reply":"2025-06-21T11:02:08.581451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T00:16:37.665501Z","iopub.execute_input":"2025-06-22T00:16:37.665758Z","iopub.status.idle":"2025-06-22T00:17:27.871875Z","shell.execute_reply.started":"2025-06-22T00:16:37.665732Z","shell.execute_reply":"2025-06-22T00:17:27.870921Z"}},"outputs":[{"name":"stderr","text":"2025-06-22 00:16:48.846917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750551409.046183      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750551409.101273      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4c4e57d6b174c4d8c9cdb27ac97c87d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53a7b21bb387478a9a46b597bdc1218d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b2ec1acfed74535854a2f0ce7b6f187"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92547a84e7884a12934dc80ac9bbe06c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e90bf32a46b468ba57013193ca26a4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cb92e4ba93046eeaefa8bf9d16f17b5"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nYour max_length is set to 142, but your input_length is only 17. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n","output_type":"stream"},{"name":"stdout","text":" 'I had a long meeting about the new product and it went on forever. I had to go on forever,' he says . 'I'm not going to let it slide,' he adds. 'I was in the middle of the meeting. I'm going to be very happy with it,' he said .\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T11:02:12.219421Z","iopub.execute_input":"2025-06-21T11:02:12.219704Z","iopub.status.idle":"2025-06-21T11:02:23.325299Z","shell.execute_reply.started":"2025-06-21T11:02:12.219678Z","shell.execute_reply":"2025-06-21T11:02:23.32446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}